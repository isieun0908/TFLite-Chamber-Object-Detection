# 머신러닝을 활용한 점적통 실시간 추적 시스템

## 요약
 이 연구에서는 모바일 장치를 활용하여 다양한 환경에서 점적통의 수액 낙하를 효과적으로 인식하기 위해서 점적통 객체 탐지 모델을 생성하였다. 다양한 배경의 점적통 사진을 수집하고 이를 바탕으로 점적통의 범위 지정을 통한 라벨링을 하여 TF lite model maker의 학습 데이터로 사용하였다. 생성한 모델을 TF Lite에 적용하여 다양한 환경에서 실험한 결과 손 떨림과 다양한 주변환경 같은 노이즈에서 높은 인식율을 보여주는 것을 확인할 수 있었다. 이 실험의 결과는 점적통 내 수액 낙하를 위한 관심영역 설정에 활용될 수 있을 것으로 판단된다.
 
 ## 연구 과정
 
1. 데이터 수집<br>
 거리와 배경이 다른 환경에서 촬영한 79개의 영상에서 1,307개의 사진 데이터를 추출하였다.

2. 라벨링<br>
LabelImg를 이용하여 사진 데이터에서 점적통의 범위를 지정하였으며, 객체의 이름은 Chamber로 설정하였다. 라벨링이 완료된 데이터는 PascalVOC형식의 XML파일로 변환하였다.

3. 학습모델 생성<br>
tensorflow lite model maker를 이용하여 tflite모델을 생성하였다. 1,307개의 사진데이터 중 train은 1,110개, validate는 130개, test로 67개의 데이터를 이용하였다.

![image](https://user-images.githubusercontent.com/80963996/164041135-1ffb2f46-10a2-4c38-b999-171368bcc049.png)<br>
[loss 변화량]

4. 모델 적용 및 실행<br>
TFLite Object Detection에 생성한 Chamber.tflite를 삽입한다. 이후 깔끔한 배경 2개와 복잡한 배경 2개의 배경에서 거리와 움직임을 변화하며 인식의 정확도를 실험하였다.

5. 결과<br>
적당한 거리에서 큰 움직임없이 인식한 경우, 배경에 상관없이 대부분의 시간동안 최고 정확률을 유지하여 99.61%의 정확도를 보였다. 가까운 거리의 경우 점적통이 가까이에 있어 초점이 맞지 않을 경우 정확률이 떨어져서 전체적인 정확률도 낮아진 것을 확인할 수 있다. 먼 거리에서는, 점적통이 작게 보여 인식 정확도는 조금 떨어졌다. 움직이면서 인식할 때는 복잡한 배경일 때는 정확률이 떨어지는 경향을 보였으나 96%이상의 정확률을 보이면서 움직임이 있을 때에도 실시간으로 정확히 추적이 가능한 것을 확인하였다.
